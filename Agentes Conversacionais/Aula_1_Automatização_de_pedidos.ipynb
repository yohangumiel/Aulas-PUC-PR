{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula 1 - Automatização de pedidos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7d43257d58b846e3b69e955b8b17c0a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_edec1951d9864b08970cfcb03a5f302b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_21b6890dad2b4dfe95b6f7e729996f81",
              "IPY_MODEL_4f1a469bb5e646c6aadac779802e4f58",
              "IPY_MODEL_f4f12545b71f496eaea7f7823dee8e30"
            ]
          }
        },
        "edec1951d9864b08970cfcb03a5f302b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21b6890dad2b4dfe95b6f7e729996f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8482eb847604fc8abaed90fd00d7621",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b352ba14418461c8c76646c7e833d52"
          }
        },
        "4f1a469bb5e646c6aadac779802e4f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f548e6bd476e467b96844155be890fe5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 24144,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 24144,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e406dd20c3a74f9282bfda9e1c110a12"
          }
        },
        "f4f12545b71f496eaea7f7823dee8e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_79ab01229c83469da665cd3507089a15",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 140k/? [00:00&lt;00:00, 3.07MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6d90bd584414bfab96c744165616266"
          }
        },
        "c8482eb847604fc8abaed90fd00d7621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b352ba14418461c8c76646c7e833d52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f548e6bd476e467b96844155be890fe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e406dd20c3a74f9282bfda9e1c110a12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79ab01229c83469da665cd3507089a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6d90bd584414bfab96c744165616266": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be8ad8f86d4a4854a5f9d26163f7e081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5c899c6089df4979bfba401f9b356234",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d642f4f15eb6402f854f0c075244ff9a",
              "IPY_MODEL_6bebfcb253424511a517c1f17f1cfb3c",
              "IPY_MODEL_d4f3ab0645df48ed9d32d9269f6202aa"
            ]
          }
        },
        "5c899c6089df4979bfba401f9b356234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d642f4f15eb6402f854f0c075244ff9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8f3cd12e77a4b3686c345f61b1bb3dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading http://nlp.stanford.edu/software/stanza/1.2.2/pt/default.zip: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9047593c997243fbaac23f987bf25d88"
          }
        },
        "6bebfcb253424511a517c1f17f1cfb3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c8a8e45ecdd2487aa031e77286324eaa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 209067526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 209067526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7bf291ac1a18420ea4a1d55fe01a2d3e"
          }
        },
        "d4f3ab0645df48ed9d32d9269f6202aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5b9ccef3e8a34c81ad39b78475c5e23e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 209M/209M [00:35&lt;00:00, 5.32MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_39a7ee91b2e848c2a4d78e8d2685859a"
          }
        },
        "c8f3cd12e77a4b3686c345f61b1bb3dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9047593c997243fbaac23f987bf25d88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8a8e45ecdd2487aa031e77286324eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7bf291ac1a18420ea4a1d55fe01a2d3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b9ccef3e8a34c81ad39b78475c5e23e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "39a7ee91b2e848c2a4d78e8d2685859a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yohangumiel/Aulas-PUC-PR/blob/main/Agentes%20Conversacionais/Aula_1_Automatiza%C3%A7%C3%A3o_de_pedidos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOK51dert0a4"
      },
      "source": [
        "# **Exemplo simples de automatização de pedidos**.\n",
        "\n",
        "## Adaptação voltada a parte de interpretação do texto para um pedido. O código original (feito pelo Prof. Lucas Oliveira) que inclusive apresenta elementos de transcrição de aúdio para texto, está disponível em https://colab.research.google.com/drive/192ttdc_MvwhGtP-_hkTVnRam8eAxBnJP?usp=sharing\n",
        "\n",
        "## Código desenvolvido por Prof. [Lucas Oliveira](https://www.linkedin.com/in/lucassilvaoliveira/) (PUC-PR) e Prof. [Yohan Gumiel](https://www.linkedin.com/in/yohan-gumiel-93b33b95/) (PUC-PR/UFMG) \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMJ-2sDYt0a5"
      },
      "source": [
        "## Contexto geral\n",
        "\n",
        "Uma grande rede de fastfood deseja automatizar completamente seus processos, desde atendimento ao cliente até a produção de seus lanches. O cliente fará seu pedido em painéis de auto-atendimento utilizando sua voz, e o pedido deve ser passado às máquinas que produzem e selecionam os produtos para entrega.\n",
        "\n",
        "A interface das máquinas prevê a leitura de um arquivo texto no seguinte formato:\n",
        "QUANTIDADE;PRODUTO;TAMANHO\n",
        "\n",
        "Defina um algoritmo que obtenha o pedido do usuário, e escreva em um arquivo-texto os produtos que devem ser preparados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YnsEWV7t0bJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87be3543-c207-4a3e-ee98-c1875e57edae"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import mac_morpho\n",
        "from nltk.tag import tnt\n",
        "from nltk import tokenize\n",
        "\n",
        "nltk.download('mac_morpho')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]   Package mac_morpho is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqSmloM5tnrk",
        "outputId": "c2748cf0-d7c4-4fe1-b081-05e806334d4a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxpLJQ4at0bN"
      },
      "source": [
        "tagged_sents = mac_morpho.tagged_sents()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL7hf_mtt0bQ"
      },
      "source": [
        "tnt_pos = tnt.TnT()\n",
        "tnt_pos.train(tagged_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eirffHgbt0bU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba706c63-e31e-4a4a-d2c8-c3b7d5e6c12d"
      },
      "source": [
        "pedido = 'Olá eu gostaria de duas batatas médias um refrigerante grande e um sanduíche pequeno'\n",
        "\n",
        "\n",
        "def get_order(pedido):\n",
        "\n",
        "    tagged_text = tnt_pos.tag(tokenize.word_tokenize(pedido, language='portuguese'))\n",
        "    print(tagged_text)\n",
        "\n",
        "    c = 0\n",
        "    for token in tagged_text:\n",
        "        print(token)\n",
        "        produto = ''\n",
        "        quantidade = '1'\n",
        "        tamanho = 'médio'\n",
        "        \n",
        "        # Se encontrou substantivo (Produto)\n",
        "        if token[1] == 'N':\n",
        "            \n",
        "            produto = token[0]\n",
        "        \n",
        "            prevTok = tagged_text[c - 1]\n",
        "            nextTok = tagged_text[c + 1]\n",
        "            \n",
        "            if prevTok[1] == 'NUM':\n",
        "                quantidade = prevTok[0]\n",
        "                \n",
        "            if nextTok[1] == 'ADJ':\n",
        "                tamanho = nextTok[0]\n",
        "                \n",
        "            pedido_interface = quantidade + \" ; \" + produto + \" ; \" + tamanho\n",
        "                       \n",
        "            print('\\nPEDIDO:', pedido_interface, '\\n')\n",
        "            \n",
        "        c += 1\n",
        "\n",
        "get_order(pedido)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Olá', 'IN'), ('eu', 'PROPESS'), ('gostaria', 'V'), ('de', 'PREP'), ('duas', 'NUM'), ('batatas', 'N'), ('médias', 'ADJ'), ('um', 'ART'), ('refrigerante', 'N'), ('grande', 'ADJ'), ('e', 'KC'), ('um', 'ART'), ('sanduíche', 'N'), ('pequeno', 'ADJ')]\n",
            "('Olá', 'IN')\n",
            "('eu', 'PROPESS')\n",
            "('gostaria', 'V')\n",
            "('de', 'PREP')\n",
            "('duas', 'NUM')\n",
            "('batatas', 'N')\n",
            "\n",
            "PEDIDO: duas ; batatas ; médias \n",
            "\n",
            "('médias', 'ADJ')\n",
            "('um', 'ART')\n",
            "('refrigerante', 'N')\n",
            "\n",
            "PEDIDO: 1 ; refrigerante ; grande \n",
            "\n",
            "('grande', 'ADJ')\n",
            "('e', 'KC')\n",
            "('um', 'ART')\n",
            "('sanduíche', 'N')\n",
            "\n",
            "PEDIDO: 1 ; sanduíche ; pequeno \n",
            "\n",
            "('pequeno', 'ADJ')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgqMygl4wKnD"
      },
      "source": [
        "## **Primeiro exercício**: analisar resultado do POS-tag (classificação gramatical), o que não reconhece e o que poderia ter problemas reconhecendo?\n",
        "\n",
        "#### **Resposta**: elementos como \"coca\" e sanduíches como \"big mac\" são tokens UNK (fora do vocabulário), ou seja, o pos-tagger não os entende como substantivos devido ao seu contexto limitado. Adicionalmente, \"uma\" é considerado um artigo e não um número.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDa2-i8Zwv90",
        "outputId": "d56394a8-2425-43d6-f82e-9f5e0ec7d3e6"
      },
      "source": [
        "pedido = 'Olá eu gostaria de um guaraná uma coca duas batatas fritas médias e quatro big macs'\n",
        "\n",
        "get_order(pedido)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Olá', 'IN'), ('eu', 'PROPESS'), ('gostaria', 'V'), ('de', 'PREP|+'), ('um', 'ART'), ('guaraná', 'N'), ('uma', 'ART'), ('coca', 'Unk'), ('duas', 'NUM'), ('batatas', 'N'), ('fritas', 'PCP'), ('médias', 'ADJ'), ('e', 'KC'), ('quatro', 'NUM'), ('big', 'N|EST'), ('macs', 'Unk')]\n",
            "('Olá', 'IN')\n",
            "('eu', 'PROPESS')\n",
            "('gostaria', 'V')\n",
            "('de', 'PREP|+')\n",
            "('um', 'ART')\n",
            "('guaraná', 'N')\n",
            "\n",
            "PEDIDO: 1 ; guaraná ; médio \n",
            "\n",
            "('uma', 'ART')\n",
            "('coca', 'Unk')\n",
            "('duas', 'NUM')\n",
            "('batatas', 'N')\n",
            "\n",
            "PEDIDO: duas ; batatas ; médio \n",
            "\n",
            "('fritas', 'PCP')\n",
            "('médias', 'ADJ')\n",
            "('e', 'KC')\n",
            "('quatro', 'NUM')\n",
            "('big', 'N|EST')\n",
            "('macs', 'Unk')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkjQod6cxg4T"
      },
      "source": [
        "## **Segunda questão**: se fosse um sistema livre (sem reconhecimento de voz) e o texto fosse inteiro em maísculo ou os itens fossem escritos em maísculo, o que aconteceria?\n",
        "\n",
        "#### **Resposta**: elementos como \"Guaraná\", \"Coca\" e \"Big Mac\" seriam considerados como substantivos próprio devido as letras maiúsculas.\n",
        "\n",
        "#### **Resposta**: se o texto inteiro fosse em maiúsculo teriam vários casos de UNK (fora do vocabulário)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIkOzStMxgWJ",
        "outputId": "b6e30cd7-49d3-449a-e8d8-ca936117049f"
      },
      "source": [
        "pedido = 'Olá eu gostaria de um Guaraná uma Coca duas batatas fritas médias e quatro Big Macs'\n",
        "\n",
        "get_order(pedido)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Olá', 'IN'), ('eu', 'PROPESS'), ('gostaria', 'V'), ('de', 'PREP|+'), ('um', 'ART'), ('Guaraná', 'NPROP'), ('uma', 'ART'), ('Coca', 'NPROP'), ('duas', 'NUM'), ('batatas', 'N'), ('fritas', 'PCP'), ('médias', 'ADJ'), ('e', 'KC'), ('quatro', 'NUM'), ('Big', 'NPROP'), ('Macs', 'NPROP')]\n",
            "('Olá', 'IN')\n",
            "('eu', 'PROPESS')\n",
            "('gostaria', 'V')\n",
            "('de', 'PREP|+')\n",
            "('um', 'ART')\n",
            "('Guaraná', 'NPROP')\n",
            "('uma', 'ART')\n",
            "('Coca', 'NPROP')\n",
            "('duas', 'NUM')\n",
            "('batatas', 'N')\n",
            "\n",
            "PEDIDO: duas ; batatas ; médio \n",
            "\n",
            "('fritas', 'PCP')\n",
            "('médias', 'ADJ')\n",
            "('e', 'KC')\n",
            "('quatro', 'NUM')\n",
            "('Big', 'NPROP')\n",
            "('Macs', 'NPROP')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Zl3DVx6x6TP",
        "outputId": "cfdcbb28-5898-4c62-9879-4b2044361f68"
      },
      "source": [
        "pedido = 'Olá eu gostaria de um Guaraná uma Coca duas batatas fritas médias e quatro Big Macs'.upper()\n",
        "\n",
        "get_order(pedido)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('OLÁ', 'Unk'), ('EU', 'Unk'), ('GOSTARIA', 'Unk'), ('DE', 'NPROP'), ('UM', 'Unk'), ('GUARANÁ', 'Unk'), ('UMA', 'Unk'), ('COCA', 'Unk'), ('DUAS', 'Unk'), ('BATATAS', 'Unk'), ('FRITAS', 'Unk'), ('MÉDIAS', 'Unk'), ('E', 'KC'), ('QUATRO', 'Unk'), ('BIG', 'Unk'), ('MACS', 'Unk')]\n",
            "('OLÁ', 'Unk')\n",
            "('EU', 'Unk')\n",
            "('GOSTARIA', 'Unk')\n",
            "('DE', 'NPROP')\n",
            "('UM', 'Unk')\n",
            "('GUARANÁ', 'Unk')\n",
            "('UMA', 'Unk')\n",
            "('COCA', 'Unk')\n",
            "('DUAS', 'Unk')\n",
            "('BATATAS', 'Unk')\n",
            "('FRITAS', 'Unk')\n",
            "('MÉDIAS', 'Unk')\n",
            "('E', 'KC')\n",
            "('QUATRO', 'Unk')\n",
            "('BIG', 'Unk')\n",
            "('MACS', 'Unk')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2CZUJg0y9Km"
      },
      "source": [
        "## **Terceira questão**: Já vimos a abordagem acima não é robusta para sanduíches do McDonalds. Como poderia ser feita uma adaptação para achar determinados sanduíches? Ainda gostariamos de fazer uso do pos-tagger para achar determinados itens, como número de sanduíches e adjetivos (como especial).\n",
        "\n",
        "#### **Resposta**: Poderia ser utilizado de expressões regulares, porém neste contexto seria interessante usar o pos-tagger para pegar números (quantidade) e adjetivos. Por este motivo foi utilizada uma estratégia de considerar sanduíches de múltiplas palavras como somente uma palavra/token e tentar achar estes tokens únicos durante a varredura. Não queremos depender do pos tagging  para marcar os sanduíches, porém queremos as unidades e adjetivos pelos pos tag.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h75_y2EPuZc0"
      },
      "source": [
        "#### **Para ajudar no código e dar um pouco de fome.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![tabela de sanduiches](https://drive.google.com/uc?export=view&id=14ZKl4btWvwqM27mpcepVY00ETYOY6e78)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R3Gn6PtzT8R",
        "outputId": "fd5eec8e-f688-4bb8-d145-352f56298fb6"
      },
      "source": [
        "pedido = 'Olá eu gostaria de um Guaraná uma Coca duas Batatas Médias e Quatro Big Macs e 2 big mac e quatro quarterão com queijo especial'\n",
        "\n",
        "\n",
        "def get_order(pedido):\n",
        "\n",
        "    pedido = pedido.lower()\n",
        "    sanduiches = ['big mac','quarterão com queijo','quarteirão com queijo','cheddar mcmelt','duplo cheeseburger','triplo cheeseburger']\n",
        "\n",
        "    list_sanduiches = ['big_mac','big_macs','quarterão_com_queijo','quarteirão_com_queijo','cheddar_mcmelt','duplo_cheeseburger','triplo_cheeseburger'] \n",
        "    # Não queremos depender do postagging para marcar os sanduíches, porém queremos as unidades e adjetivos pelo pos tag. Poderiamos refinar as regex (números), por exemplo: conversão de um para 1\n",
        "\n",
        "    list_refrigerantes = ['coca','guaraná']\n",
        "\n",
        "    for sanduiche in sanduiches:\n",
        "        pedido = pedido.replace(sanduiche,'_'.join(sanduiche.split()))\n",
        "\n",
        "    print(pedido)\n",
        "\n",
        "    tagged_text = tnt_pos.tag(tokenize.word_tokenize(pedido, language='portuguese'))\n",
        "    print(tagged_text)\n",
        "\n",
        "    c = 0\n",
        "    for token in tagged_text:\n",
        "        print(token)\n",
        "        produto = ''\n",
        "        quantidade = ''\n",
        "        tamanho = ''\n",
        "        \n",
        "        # Se encontrou substantivo (Produto)\n",
        "        if token[1] == 'N' or  token[0] in list_sanduiches or token[0] in list_refrigerantes:\n",
        "            \n",
        "            produto = token[0]\n",
        "        \n",
        "            prevTok = tagged_text[c - 1]\n",
        "            nextTok = tagged_text[c + 1]\n",
        "            \n",
        "            if prevTok[1] == 'NUM':\n",
        "                quantidade = prevTok[0]\n",
        "                \n",
        "            if nextTok[1] == 'ADJ':\n",
        "                tamanho = nextTok[0]\n",
        "                \n",
        "            pedido_interface = quantidade + \" ; \" + produto + \" ; \" + tamanho\n",
        "                       \n",
        "            print('\\nPEDIDO:', pedido_interface, '\\n')\n",
        "            \n",
        "        c += 1\n",
        "\n",
        "get_order(pedido)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "olá eu gostaria de um guaraná uma coca duas batatas médias e quatro big_macs e 2 big_mac e quatro quarterão_com_queijo especial\n",
            "[('olá', 'Unk'), ('eu', 'PROPESS'), ('gostaria', 'V'), ('de', 'PREP|+'), ('um', 'ART'), ('guaraná', 'N'), ('uma', 'ART'), ('coca', 'Unk'), ('duas', 'NUM'), ('batatas', 'N'), ('médias', 'ADJ'), ('e', 'KC'), ('quatro', 'NUM'), ('big_macs', 'Unk'), ('e', 'KC'), ('2', 'NUM'), ('big_mac', 'Unk'), ('e', 'KC'), ('quatro', 'NUM'), ('quarterão_com_queijo', 'Unk'), ('especial', 'ADJ')]\n",
            "('olá', 'Unk')\n",
            "('eu', 'PROPESS')\n",
            "('gostaria', 'V')\n",
            "('de', 'PREP|+')\n",
            "('um', 'ART')\n",
            "('guaraná', 'N')\n",
            "\n",
            "PEDIDO:  ; guaraná ;  \n",
            "\n",
            "('uma', 'ART')\n",
            "('coca', 'Unk')\n",
            "\n",
            "PEDIDO:  ; coca ;  \n",
            "\n",
            "('duas', 'NUM')\n",
            "('batatas', 'N')\n",
            "\n",
            "PEDIDO: duas ; batatas ; médias \n",
            "\n",
            "('médias', 'ADJ')\n",
            "('e', 'KC')\n",
            "('quatro', 'NUM')\n",
            "('big_macs', 'Unk')\n",
            "\n",
            "PEDIDO: quatro ; big_macs ;  \n",
            "\n",
            "('e', 'KC')\n",
            "('2', 'NUM')\n",
            "('big_mac', 'Unk')\n",
            "\n",
            "PEDIDO: 2 ; big_mac ;  \n",
            "\n",
            "('e', 'KC')\n",
            "('quatro', 'NUM')\n",
            "('quarterão_com_queijo', 'Unk')\n",
            "\n",
            "PEDIDO: quatro ; quarterão_com_queijo ; especial \n",
            "\n",
            "('especial', 'ADJ')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL6B3Ix0mIbc"
      },
      "source": [
        "#### No trecho de código abaixo foi adicionada uma regra para considerar \"uma\" e \"um\" como números e não artigos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiWBHLSU3HWV",
        "outputId": "9b444ff5-f5aa-466c-c42b-0d7114b80a4d"
      },
      "source": [
        "pedido = 'Olá eu gostaria de um Guaraná uma Coca duas Batatas Médias e Quatro Big Macs e 2 big mac e quatro quarterão com queijo especial'\n",
        "\n",
        "\n",
        "def get_order(pedido):\n",
        "\n",
        "    pedido = pedido.lower()\n",
        "    sanduiches = ['big mac','quarterão com queijo','quarteirão com queijo','cheddar mcmelt','duplo cheeseburger','triplo cheeseburger']\n",
        "\n",
        "    list_sanduiches = ['big_mac','big_macs','quarterão_com_queijo','quarteirão_com_queijo','cheddar_mcmelt','duplo_cheeseburger','triplo_cheeseburger'] # não quero depender do postagging para marcar os sanduíches, porém quero as unidades pelo Postag, poderia refinar as regex (números), por exemplo: conversão de um para 1\n",
        "\n",
        "    list_refrigerantes = ['coca','guaraná']\n",
        "\n",
        "    for sanduiche in sanduiches:\n",
        "        pedido = pedido.replace(sanduiche,'_'.join(sanduiche.split()))\n",
        "\n",
        "    print(pedido)\n",
        "\n",
        "    tagged_text = tnt_pos.tag(tokenize.word_tokenize(pedido, language='portuguese'))\n",
        "\n",
        "\n",
        "    tagged_text = [list(elem) for elem in tagged_text]\n",
        "\n",
        "    print(tagged_text)\n",
        "\n",
        "    for token in list(tagged_text):\n",
        "        if token[0] == 'um' or token[0] == 'uma':\n",
        "            token[1] = 'NUM'\n",
        "\n",
        "    print(tagged_text)\n",
        "\n",
        "    c = 0\n",
        "    for token in tagged_text:\n",
        "        print(token)\n",
        "        produto = ''\n",
        "        quantidade = ''\n",
        "        tamanho = ''\n",
        "        \n",
        "        # Se encontrou substantivo (Produto)\n",
        "        if token[1] == 'N' or  token[0] in list_sanduiches or token[0] in list_refrigerantes:\n",
        "            \n",
        "            produto = token[0]\n",
        "        \n",
        "            prevTok = tagged_text[c - 1]\n",
        "            nextTok = tagged_text[c + 1]\n",
        "            \n",
        "            if prevTok[1] == 'NUM':\n",
        "                quantidade = prevTok[0]\n",
        "                \n",
        "            if nextTok[1] == 'ADJ':\n",
        "                tamanho = nextTok[0]\n",
        "                \n",
        "            pedido_interface = quantidade + \" ; \" + produto + \" ; \" + tamanho\n",
        "                       \n",
        "            print('\\nPEDIDO:', pedido_interface, '\\n')\n",
        "\n",
        "            \n",
        "        c += 1\n",
        "\n",
        "get_order(pedido)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "olá eu gostaria de um guaraná uma coca duas batatas médias e quatro big_macs e 2 big_mac e quatro quarterão_com_queijo especial\n",
            "[['olá', 'Unk'], ['eu', 'PROPESS'], ['gostaria', 'V'], ['de', 'PREP|+'], ['um', 'ART'], ['guaraná', 'N'], ['uma', 'ART'], ['coca', 'Unk'], ['duas', 'NUM'], ['batatas', 'N'], ['médias', 'ADJ'], ['e', 'KC'], ['quatro', 'NUM'], ['big_macs', 'Unk'], ['e', 'KC'], ['2', 'NUM'], ['big_mac', 'Unk'], ['e', 'KC'], ['quatro', 'NUM'], ['quarterão_com_queijo', 'Unk'], ['especial', 'ADJ']]\n",
            "[['olá', 'Unk'], ['eu', 'PROPESS'], ['gostaria', 'V'], ['de', 'PREP|+'], ['um', 'NUM'], ['guaraná', 'N'], ['uma', 'NUM'], ['coca', 'Unk'], ['duas', 'NUM'], ['batatas', 'N'], ['médias', 'ADJ'], ['e', 'KC'], ['quatro', 'NUM'], ['big_macs', 'Unk'], ['e', 'KC'], ['2', 'NUM'], ['big_mac', 'Unk'], ['e', 'KC'], ['quatro', 'NUM'], ['quarterão_com_queijo', 'Unk'], ['especial', 'ADJ']]\n",
            "['olá', 'Unk']\n",
            "['eu', 'PROPESS']\n",
            "['gostaria', 'V']\n",
            "['de', 'PREP|+']\n",
            "['um', 'NUM']\n",
            "['guaraná', 'N']\n",
            "\n",
            "PEDIDO: um ; guaraná ;  \n",
            "\n",
            "['uma', 'NUM']\n",
            "['coca', 'Unk']\n",
            "\n",
            "PEDIDO: uma ; coca ;  \n",
            "\n",
            "['duas', 'NUM']\n",
            "['batatas', 'N']\n",
            "\n",
            "PEDIDO: duas ; batatas ; médias \n",
            "\n",
            "['médias', 'ADJ']\n",
            "['e', 'KC']\n",
            "['quatro', 'NUM']\n",
            "['big_macs', 'Unk']\n",
            "\n",
            "PEDIDO: quatro ; big_macs ;  \n",
            "\n",
            "['e', 'KC']\n",
            "['2', 'NUM']\n",
            "['big_mac', 'Unk']\n",
            "\n",
            "PEDIDO: 2 ; big_mac ;  \n",
            "\n",
            "['e', 'KC']\n",
            "['quatro', 'NUM']\n",
            "['quarterão_com_queijo', 'Unk']\n",
            "\n",
            "PEDIDO: quatro ; quarterão_com_queijo ; especial \n",
            "\n",
            "['especial', 'ADJ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOTOEOPHmiQ1"
      },
      "source": [
        "## **Quarta questão**: Se usassemos outro pos tagger, como o Stanza, será que haveria alguma diferença?\n",
        "\n",
        "#### **Resposta**: Neste contexto não haveria uma mudança muito significativa. Pelos testes feitos ambos tem dificuldades com o \"um\" e \"uma\" e com sanduíches específicos como \"big mac\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387,
          "referenced_widgets": [
            "7d43257d58b846e3b69e955b8b17c0a8",
            "edec1951d9864b08970cfcb03a5f302b",
            "21b6890dad2b4dfe95b6f7e729996f81",
            "4f1a469bb5e646c6aadac779802e4f58",
            "f4f12545b71f496eaea7f7823dee8e30",
            "c8482eb847604fc8abaed90fd00d7621",
            "8b352ba14418461c8c76646c7e833d52",
            "f548e6bd476e467b96844155be890fe5",
            "e406dd20c3a74f9282bfda9e1c110a12",
            "79ab01229c83469da665cd3507089a15",
            "a6d90bd584414bfab96c744165616266",
            "be8ad8f86d4a4854a5f9d26163f7e081",
            "5c899c6089df4979bfba401f9b356234",
            "d642f4f15eb6402f854f0c075244ff9a",
            "6bebfcb253424511a517c1f17f1cfb3c",
            "d4f3ab0645df48ed9d32d9269f6202aa",
            "c8f3cd12e77a4b3686c345f61b1bb3dc",
            "9047593c997243fbaac23f987bf25d88",
            "c8a8e45ecdd2487aa031e77286324eaa",
            "7bf291ac1a18420ea4a1d55fe01a2d3e",
            "5b9ccef3e8a34c81ad39b78475c5e23e",
            "39a7ee91b2e848c2a4d78e8d2685859a"
          ]
        },
        "id": "CLqVt_ay4Ts0",
        "outputId": "25480b80-a01b-45a7-c6df-a70100470feb"
      },
      "source": [
        "!pip install stanza\n",
        "\n",
        "import stanza\n",
        "stanza.download('pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stanza\n",
            "  Downloading stanza-1.2.3-py3-none-any.whl (342 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 40 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 51 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 61 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 71 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 81 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 92 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 102 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 112 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 122 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 133 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 143 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 153 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 163 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 174 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 184 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 194 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 204 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 215 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 225 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 235 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 245 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 256 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 266 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 276 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 286 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 296 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 307 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 317 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 327 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 337 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 342 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.62.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Installing collected packages: stanza\n",
            "Successfully installed stanza-1.2.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d43257d58b846e3b69e955b8b17c0a8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json:   0%|   …"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-17 19:34:16 INFO: Downloading default packages for language: pt (Portuguese)...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be8ad8f86d4a4854a5f9d26163f7e081",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading http://nlp.stanford.edu/software/stanza/1.2.2/pt/default.zip:   0%|          | 0.00/209M [00:00<?,…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-17 19:34:54 INFO: Finished downloading models and saved to /root/stanza_resources.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyZyZFdQ4UM1",
        "outputId": "f3fc4d15-cf2e-46de-8715-d4d88246d351"
      },
      "source": [
        "stanza_pt = stanza.Pipeline('pt', tokenize_pretokenized=True, use_gpu= True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-08-17 19:34:54 INFO: Loading these models for language: pt (Portuguese):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | bosque  |\n",
            "| mwt       | bosque  |\n",
            "| pos       | bosque  |\n",
            "| lemma     | bosque  |\n",
            "| depparse  | bosque  |\n",
            "=======================\n",
            "\n",
            "2021-08-17 19:34:54 INFO: Use device: cpu\n",
            "2021-08-17 19:34:54 INFO: Loading: tokenize\n",
            "2021-08-17 19:34:54 INFO: Loading: mwt\n",
            "2021-08-17 19:34:55 INFO: Loading: pos\n",
            "2021-08-17 19:34:55 INFO: Loading: lemma\n",
            "2021-08-17 19:34:55 INFO: Loading: depparse\n",
            "2021-08-17 19:34:55 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZluT56m4oyJ"
      },
      "source": [
        "def get_order(pedido):\n",
        "    \n",
        "\n",
        "    tagged_text = tnt_pos.tag(tokenize.word_tokenize(pedido, language='portuguese'))\n",
        "\n",
        "    tagged_text_stanza = []\n",
        "\n",
        "    doc = stanza_pt([tokenize.word_tokenize(pedido, language='portuguese')])              \n",
        "    for sent in doc.sentences:\n",
        "        for word in sent.words:\n",
        "            tagged_text_stanza.append((word.text,word.pos))\n",
        "\n",
        "\n",
        "    print('Mac-morpho:\\n', tagged_text)\n",
        "    print('Stanza:\\n', tagged_text_stanza)\n",
        "\n",
        "\n",
        "    c = 0\n",
        "    for token in tagged_text_stanza:\n",
        "        print(token)\n",
        "        \n",
        "        produto = ''\n",
        "        quantidade = ''\n",
        "        tamanho = ''\n",
        "        \n",
        "        # Se encontrou substantivo (Produto)\n",
        "        if token[1] == 'NOUN':\n",
        "            \n",
        "            produto = token[0]\n",
        "        \n",
        "            prevTok = tagged_text_stanza[c - 1]\n",
        "            nextTok = tagged_text_stanza[c + 1]\n",
        "            \n",
        "            if prevTok[1] == 'NUM':\n",
        "                quantidade = prevTok[0]\n",
        "                \n",
        "            if nextTok[1] == 'ADJ':\n",
        "                tamanho = nextTok[0]\n",
        "                \n",
        "            pedido_interface = quantidade + \" ; \" + produto + \" ; \" + tamanho \n",
        "            \n",
        "            print('\\nPEDIDO:', pedido_interface, '\\n')\n",
        "            \n",
        "        c += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOVpuj4-41zl",
        "outputId": "46b20235-9e35-4e13-cdb2-93404cd69824"
      },
      "source": [
        "pedido = 'Olá eu gostaria de um refrigerante pequeno duas batatas médias e quatro sanduíches pequenos'\n",
        "get_order(pedido)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mac-morpho:\n",
            " [('Olá', 'IN'), ('eu', 'PROPESS'), ('gostaria', 'V'), ('de', 'PREP|+'), ('um', 'ART'), ('refrigerante', 'N'), ('pequeno', 'ADJ'), ('duas', 'NUM'), ('batatas', 'N'), ('médias', 'ADJ'), ('e', 'KC'), ('quatro', 'NUM'), ('sanduíches', 'N'), ('pequenos', 'ADJ')]\n",
            "Stanza:\n",
            " [('Olá', 'ADV'), ('eu', 'PRON'), ('gostaria', 'VERB'), ('de', 'ADP'), ('um', 'DET'), ('refrigerante', 'NOUN'), ('pequeno', 'ADJ'), ('duas', 'NUM'), ('batatas', 'NOUN'), ('médias', 'ADJ'), ('e', 'CCONJ'), ('quatro', 'NUM'), ('sanduíches', 'NOUN'), ('pequenos', 'ADJ')]\n",
            "('Olá', 'ADV')\n",
            "('eu', 'PRON')\n",
            "('gostaria', 'VERB')\n",
            "('de', 'ADP')\n",
            "('um', 'DET')\n",
            "('refrigerante', 'NOUN')\n",
            "\n",
            "PEDIDO:  ; refrigerante ; pequeno \n",
            "\n",
            "('pequeno', 'ADJ')\n",
            "('duas', 'NUM')\n",
            "('batatas', 'NOUN')\n",
            "\n",
            "PEDIDO: duas ; batatas ; médias \n",
            "\n",
            "('médias', 'ADJ')\n",
            "('e', 'CCONJ')\n",
            "('quatro', 'NUM')\n",
            "('sanduíches', 'NOUN')\n",
            "\n",
            "PEDIDO: quatro ; sanduíches ; pequenos \n",
            "\n",
            "('pequenos', 'ADJ')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SlntI4KnzQN",
        "outputId": "06a12c32-7092-4a3a-a1fe-b49c85804567"
      },
      "source": [
        "pedido = 'Olá eu gostaria de um guaraná uma coca duas batatas médias e quatro big macs e 2 big mac e quatro quarterão com queijo especial'\n",
        "\n",
        "get_order(pedido)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mac-morpho:\n",
            " [('Olá', 'IN'), ('eu', 'PROPESS'), ('gostaria', 'V'), ('de', 'PREP|+'), ('um', 'ART'), ('guaraná', 'N'), ('uma', 'ART'), ('coca', 'Unk'), ('duas', 'NUM'), ('batatas', 'N'), ('médias', 'ADJ'), ('e', 'KC'), ('quatro', 'NUM'), ('big', 'N|EST'), ('macs', 'Unk'), ('e', 'KC'), ('2', 'N'), ('big', 'ADJ|EST'), ('mac', 'Unk'), ('e', 'KC'), ('quatro', 'NUM'), ('quarterão', 'Unk'), ('com', 'PREP'), ('queijo', 'N'), ('especial', 'ADJ')]\n",
            "Stanza:\n",
            " [('Olá', 'ADV'), ('eu', 'PRON'), ('gostaria', 'VERB'), ('de', 'ADP'), ('um', 'DET'), ('guaraná', 'NOUN'), ('uma', 'DET'), ('coca', 'NOUN'), ('duas', 'NUM'), ('batatas', 'NOUN'), ('médias', 'ADJ'), ('e', 'CCONJ'), ('quatro', 'NUM'), ('big', 'X'), ('macs', 'X'), ('e', 'CCONJ'), ('2', 'NUM'), ('big', 'X'), ('mac', 'X'), ('e', 'CCONJ'), ('quatro', 'NUM'), ('quarterão', 'VERB'), ('com', 'ADP'), ('queijo', 'NOUN'), ('especial', 'ADJ')]\n",
            "('Olá', 'ADV')\n",
            "('eu', 'PRON')\n",
            "('gostaria', 'VERB')\n",
            "('de', 'ADP')\n",
            "('um', 'DET')\n",
            "('guaraná', 'NOUN')\n",
            ";guaraná;\n",
            "('uma', 'DET')\n",
            "('coca', 'NOUN')\n",
            ";coca;\n",
            "('duas', 'NUM')\n",
            "('batatas', 'NOUN')\n",
            "duas;batatas;médias\n",
            "('médias', 'ADJ')\n",
            "('e', 'CCONJ')\n",
            "('quatro', 'NUM')\n",
            "('big', 'X')\n",
            "('macs', 'X')\n",
            "('e', 'CCONJ')\n",
            "('2', 'NUM')\n",
            "('big', 'X')\n",
            "('mac', 'X')\n",
            "('e', 'CCONJ')\n",
            "('quatro', 'NUM')\n",
            "('quarterão', 'VERB')\n",
            "('com', 'ADP')\n",
            "('queijo', 'NOUN')\n",
            ";queijo;especial\n",
            "('especial', 'ADJ')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFLvEHBquEgD"
      },
      "source": [
        "### Referências\n",
        "* [Reconhecimento de Voz com Python: Faça seu primeiro Olá Mundo com Speech Recognition!](https://medium.com/brasil-ai/reconhecimento-voz-python-35a5023767ca)"
      ]
    }
  ]
}